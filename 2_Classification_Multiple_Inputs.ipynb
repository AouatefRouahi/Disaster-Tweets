{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab94bd61-d958-47c8-84e2-ce55b81b54ce",
   "metadata": {},
   "source": [
    "# Disaster Tweets\n",
    "------\n",
    ">In this Third phase of the project, we will:  \n",
    ">> define another model that takes into account the **metadata** extracted from the text and the **text** itself to classify tweets.  \n",
    ">> The idea is to define and train a model that takes mixed data inputs:   \n",
    ">>> **Numerical MetaData** and   \n",
    ">>> **Tweets Text**   \n",
    "\n",
    ">> to give one output, that is, the final prediction given these pieces of data.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcdb466-5a51-41a1-a93b-ffcd5c01c0a6",
   "metadata": {},
   "source": [
    "<img src=\"img/mlp_lstm.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51ed446-8faa-4f90-a862-601c65418820",
   "metadata": {},
   "source": [
    ">In order to build the multi-input neural network we need two branches:\n",
    ">> The first branch is a **Multi-layer Perceptron (MLP)** designed to handle the **numerical** metadata  \n",
    "The second branch is a **Long Short-Term Memory (LSTM)** Network to operate over the **text** data\n",
    "\n",
    "> These branches are then **concatenated** together to form the final multi-input model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f98003",
   "metadata": {},
   "source": [
    "# Import useful Librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8331ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning librairies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# global params\n",
    "pre_file_path = \"data/pre_train.csv\"\n",
    "models_path = 'models/'\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9449b019",
   "metadata": {},
   "source": [
    "# Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d0254b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>at_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_keyword</th>\n",
       "      <th>keyword_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near ronge sask canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near ronge sask canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword                                               text  target  \\\n",
       "0     NaN  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1     NaN             Forest fire near La Ronge Sask. Canada       1   \n",
       "\n",
       "   word_count  unique_word_count  stop_word_count  url_count  char_count  \\\n",
       "0          13                 13                8          0          69   \n",
       "1           7                  7                0          0          38   \n",
       "\n",
       "   punctuation_count  hashtag_count  at_count  \\\n",
       "0                  1              1         0   \n",
       "1                  1              0         0   \n",
       "\n",
       "                             clean_text clean_keyword  \\\n",
       "0  deed reason earthquake allah forgive           NaN   \n",
       "1    forest fire near ronge sask canada           NaN   \n",
       "\n",
       "                            keyword_text  \n",
       "0   deed reason earthquake allah forgive  \n",
       "1     forest fire near ronge sask canada  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(pre_file_path)\n",
    "tweets.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d3fbe-9b0c-4985-9a9e-55ad2357c4d3",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae9037-23ca-43f8-b384-150cfc691fe8",
   "metadata": {},
   "source": [
    "##  Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18682ff2-67c8-4ffb-ac4e-2f792a9b4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5_000\n",
    "\n",
    "#build the vocab and keep the K most common word based on word frequency (K = max_features)\n",
    "# max_features+ 1(1 OOV token)\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = max_features + 1)\n",
    "tokenizer.fit_on_texts(tweets[\"keyword_text\"])\n",
    "\n",
    "# Transforms each text to a sequence of integers, only the K most common words will be transformed (K = max_features)\n",
    "tweets[\"tweet_encoded\"] = tokenizer.texts_to_sequences(tweets.keyword_text)\n",
    "\n",
    "# check whether we have empty lists\n",
    "tweets['length'] = tweets['tweet_encoded'].apply(lambda x : len(x))\n",
    "tweets = tweets[tweets[\"length\"]!=0]\n",
    "\n",
    "# add padding so that all sequences have the same length --> a numpy array of equal length sequences\n",
    "tweet_pad = tf.keras.preprocessing.sequence.pad_sequences(tweets.tweet_encoded, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22404a3d-e41c-4653-aeb4-473bbcfcde39",
   "metadata": {},
   "source": [
    "##  Numerical MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "905c2375-e1cd-4acc-8888-8f7bbf2d62ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns related to the numerical metadata\n",
    "cols = ['word_count', 'unique_word_count',\n",
    "       'stop_word_count', 'url_count', 'char_count', 'punctuation_count',\n",
    "       'hashtag_count', 'at_count', 'target']\n",
    "\n",
    "# split the whole data into train and test sets\n",
    "trainMetaX, testMetaX, trainTextX, testTextX = train_test_split(tweets[cols], tweet_pad, test_size=0.2, random_state=seed)\n",
    "\n",
    "# get the target values\n",
    "trainY = trainMetaX.target.values\n",
    "testY = testMetaX.target.values\n",
    "\n",
    "# standardize the numerical metadata\n",
    "trainMetaX = trainMetaX.drop(columns=['target'])\n",
    "testMetaX = testMetaX.drop(columns=['target'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "trainMetaX = scaler.fit_transform(trainMetaX)\n",
    "testMetaX = scaler.transform(testMetaX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b9220-c4b8-48d4-8302-2b733e37e52a",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac67e3-1d30-46c5-829a-3215e8fdc9e1",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56b4f53f-3dd2-4c5c-9119-5c5192a41669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for the multi-layer perceptron (deep feed forword network)\n",
    "# input = Numerical Metadata\n",
    "def create_mlp(dim, regress=False):\n",
    "    model = tf.keras.Sequential()\n",
    "    # input layer\n",
    "    model.add(tf.keras.layers.Dense(32, input_dim=dim, activation=\"relu\"))\n",
    "    # hidden layer\n",
    "    model.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
    "    # check to see if the output regression node should be added\n",
    "    if regress:\n",
    "        model.add(tf.keras.layers.Dense(1, activation=\"linear\"))\n",
    "    # return our model\n",
    "    return model\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# helper for the LSTM network\n",
    "# input = Text data\n",
    "def create_lstm(vocab_size, seq_length, regress=False):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(input_dim = vocab_size +1, output_dim = 16, input_length = seq_length))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.LSTM(units = 32, return_sequences=False)) \n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    if regress:\n",
    "         model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d00a9b-a948-4058-84cb-1d4815357620",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe08ea9b-fabd-4afe-99f4-a6166a619863",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = tweet_pad[0].shape[0]\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "\n",
    "mlp = create_mlp(trainMetaX.shape[1], regress=False)\n",
    "lstm = create_lstm(vocab_size, seq_length, regress=False)\n",
    "\n",
    "combinedInput = tf.keras.layers.concatenate([mlp.output, lstm.output])\n",
    "x = tf.keras.layers.Dense(4, activation=\"relu\")(combinedInput)\n",
    "x = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[mlp.input, lstm.input], outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb915031-9fd2-4448-91e5-aa6920dd0372",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07bfa14-d9da-489d-b8ea-79ab0de3422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer= tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics = [tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6a227-d455-4499-a107-a8a53e37f01d",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae286428-57f1-44cc-955c-66268cd0c56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.1984 - binary_accuracy: 0.9443 - val_loss: 1.2399 - val_binary_accuracy: 0.7641\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.1989 - binary_accuracy: 0.9497 - val_loss: 1.3876 - val_binary_accuracy: 0.7668\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2051 - binary_accuracy: 0.9512 - val_loss: 1.2451 - val_binary_accuracy: 0.7733\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.1922 - binary_accuracy: 0.9540 - val_loss: 1.2460 - val_binary_accuracy: 0.7727\n"
     ]
    }
   ],
   "source": [
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 3)\n",
    "\n",
    "history = model.fit(\n",
    "    x = [trainMetaX, trainTextX], y = trainY,\n",
    "    validation_data = ([testMetaX, testTextX], testY),\n",
    "    epochs=10, \n",
    "    batch_size=32,\n",
    "    callbacks = [es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ed572ab-2cd2-4c38-8d7e-6d26c4244c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------- Train Accuracy ------------------------------\n",
      "\n",
      "Mean:  0.9498193114995956\n",
      "Std:  0.003527710657804122\n",
      "\n",
      "---------------------------- Validation Accuracy ------------------------------\n",
      "\n",
      "Mean:  0.7692181169986725\n",
      "Std:  0.003897440609891768\n"
     ]
    }
   ],
   "source": [
    "print('\\n---------------------------- Train Accuracy ------------------------------\\n')\n",
    "print('Mean: ', np.mean(history.history['binary_accuracy']))\n",
    "print('Std: ', np.std(history.history['binary_accuracy']))\n",
    "print('\\n---------------------------- Validation Accuracy ------------------------------\\n')\n",
    "print('Mean: ', np.mean(history.history['val_binary_accuracy']))\n",
    "print('Std: ', np.std(history.history['val_binary_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec6378-c56e-4a3b-b9e8-4a09686f19a6",
   "metadata": {},
   "source": [
    ">ðŸ—’ With the first model that is only trained on the text data, we obtained a mean accuracy of 0.69 and a std of 0.02 over the validation set. With the combined model that takes into account the numerical metadata, we got a mean accuracy of 0.76 and a std of 0.004. The second model improves the prediction accuracy by 7%.\n",
    "\n",
    "> More tuning may give better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8cfef5-cf72-4bac-8da8-1296d210d5d4",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f9ff965",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(models_path + \"model_lstm_mlp.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
